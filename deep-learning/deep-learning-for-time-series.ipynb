{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5da29a",
   "metadata": {},
   "source": [
    "# Deep Learning for Time Series\n",
    "\n",
    "Deep learning for **time series** is a relatively new but promising initiative. As it is a very flexible technique, it can be advantageous for analyzing **time series**. In addition to being promising, the technique makes it possible to model extremely complex and non-linear temporal behaviors without the need to assume their functional formats - which could be a game changer for non-statistical forecasting techniques.\n",
    "\n",
    "Deep learning represents a subarea of ​​machine learning in which a \"graph\" is constructed to connect input nodes into a complicated structure of nodes and edges. When moving from one node to another via an edge, a value is multiplied by the weight of that edge and then typically passes through some type of non-linear activation function. It's this nonlinear activation function that makes deep learning so interesting: it allows us to fit extremely complex nonlinear data, something that hasn't been done so successfully before.\n",
    "\n",
    "Deep learning has mostly taken hold over the last ten years, as improvements in commercially available hardware have been combined with vast amounts of data to make this kind of heavy model tuning possible. Deep learning models can have millions of parameters. So one way to understand them is to imagine any graph with all kinds of matrix multiplications and nonlinear transformations, and then imagine a smart optimizer that optimizes its model on a small group of data at a time, continually adjusting the weights of that data. large model so that they generate increasingly better results.\n",
    "\n",
    "Deep learning has not yet generated surprising prediction results as it has in other areas, such as image processing and natural language processing. Despite this, there is good reason to be optimistic that deep learning will ultimately advance the art of prediction while minimizing the sensitive and highly uniform nature of the assumptions and technical requirements common to traditional prediction models.\n",
    "\n",
    "Most of the hurdles of data preprocessing to adjust a model's assumptions disappear when using deep learning models:\n",
    "- stationarity is not required;\n",
    "- the need to develop the art and skill of selecting parameters, such as evaluating the seasonality and order of a seasonal ARIMA model, disappears;\n",
    "- the need to develop a hypothesis about the underlying dynamics of a system, which often helps in state space modeling, disappears.\n",
    "\n",
    "Deep learning is even more flexible for several reasons:\n",
    "- many machine learning algorithms tend to be quite sensitive in terms of dimensionality and types of input data needed for the training algorithm to work. In contrast, deep learning is quite flexible regarding the model and nature of the inputs;\n",
    "- heterogeneous data can be challenging with many commonly used machine learning techniques, despite being commonly used with deep learning models;\n",
    "- while deep learning has a lot of flexibility when it comes to developing specific architectures for temporal data, machine learning models are rarely developed for **time series** problems.\n",
    "\n",
    "However, deep learning is not a cure-all. While stationarity is not a requirement for deep learning applied to **time series**, in practice deep learning does not fit data well with a trend unless standard architectures are modified to fit the trend . That is, we will still need to preprocess our data or our technique.\n",
    "\n",
    "What's more, deep learning does best with numeric inputs in different channels, all scaled to similar values between -1 and 1. This means you'll need to preprocess your data, although theoretically it's not necessary. You'll also need to do some preprocessing to avoid lookahead, something the deep learning community generally doesn't spend much time perfecting.\n",
    "\n",
    "Finally, deep learning optimization and modeling techniques for time-oriented neural networks (the largest class of which are recurrent neural networks or RNNs) are not as well developed as those for image processing (the largest class of which are convulsional neural networks, or CNNs). That is, you will find less guidance on best practices and general rules for selecting and training an architecture than you would for non-temporal tasks.\n",
    "\n",
    "In addition to these difficulties of applying deep learning to **time series**, you will discover the advantages of doing so have their positive and negative sides. For starters, deep learning performance for **time series** does not invariably outperform more traditional **time series** accuracy and classification methods. In fact, prediction is a ripe area for deep learning improvements.\n",
    "\n",
    "However, there are reasons to expect immediate and long-term benefits from adding deep rendering to your **time series** analysis toolset. First, large technology companies began to promote deep learning for **time series** services with custom architectures they developed in-house, often considering specific modeling tasks. You can use these services or combine them with your own analytics to get good performance.\n",
    "\n",
    "Second, you might have a dataset that works really well with deep learning for **time series**. In general, the stronger the signal-to-noise ratio, the better its performance. Next, we will briefly review the concepts that inspired and supported deep learning as a mathematical and computer science pursuit, as well as concrete examples of code to apply to deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1cee4",
   "metadata": {},
   "source": [
    "## Conceitos de Aprendizado Profundo\n",
    "\n",
    "O aprendizado profundo tem raízes em inúmeros campos de atuação. Buscou-se inspiração nas ciências biológicas, e os cientistas da computação, assim como os analistas quantitativos, viviam questionando se a forma de construir máquinas inteligentes era, no final das contas, simular um cérebro com suas redes neurais que disparavam respostas a determinados gatilhos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac21bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
