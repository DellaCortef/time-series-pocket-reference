{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42f11db",
   "metadata": {},
   "source": [
    "# Simulating Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd366a",
   "metadata": {},
   "source": [
    "For now, we've seen where to find **time series** data and how to process it. Now let's look at how to create **time series** data through simulation. \n",
    "\n",
    "We will divide it into 3 parts. In the first, we will compare **time series** data simulations with other types of data simulations, seeing which specific new areas of interest come to light when considering the passage of time. In the second part, we will look at some code-based simulations. Finally, in the third part, we will analyze some general trends in **time series** simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e867bf73",
   "metadata": {},
   "source": [
    "Specific examples for generating different types of **time series** data:\n",
    "- we will simulate the email opening and donation behavior of members of a non-profit organization over several years;\n",
    "- we will simulate events in a taxi fleet of a thousand vehicles with various shift start times and passenger boarding frequencies;\n",
    "- we will simulate step by step the evolution of the magnetic state of a solid at a given temperature and size using the relevant laws of physics;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75590094",
   "metadata": {},
   "source": [
    "These three examples correlate to three classes of **time series** simulations:\n",
    "- *heuristic simulations:*\n",
    "    - we decide how the world should work, ensuring logic and coding, rule by rule;\n",
    "- *discrete event simulations (SED):*\n",
    "    - we will create individual actors that follow certain rules in our universe and then implement these actors to see how the universe evolves over time;\n",
    "- *simulations based on laws of physics:*\n",
    "    - we will apply the laws of physics to see how a system evolves over time;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd7b33",
   "metadata": {},
   "source": [
    "### Why is Time Series Simulation Special?\n",
    "\n",
    "Data simulation is an area of ​​Data Science that is rarely taught despite being an essential skill for **time series** data. This is one of the negative aspects of temporal data: no two data points in the same time series are exactly comparable, as these points occur at different times. If we want to think about *what could have happened in a given time*, we enter the world of simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87cab4d",
   "metadata": {},
   "source": [
    "### Simulation versus Prediction\n",
    "\n",
    "Simulation and forecasting are similar practices. In both, we must formulate hypotheses about the dynamics and parameters of the underlying system and then extrapolate from these hypotheses in order to generate data points. However, there are important differences to consider when learning and developing simulations rather than predictions:\n",
    "- it may be easier to integrate qualitative observations into a simulation than into a prediction;\n",
    "- simulations are run at scale, so that we can analyze several alternative scenarios, while forecasts must be generated with more care;\n",
    "- the risks of simulations are lower than predictions, as there are no lives or resources at stake. Therefore, you can be more creative and exploratory in your initial rounds of simulations. Obviously, sooner or later, you want to be sure that you can justify how you build your simulations, just as you justify your predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb7c4ff",
   "metadata": {},
   "source": [
    "### Installing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eeeb520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38914300",
   "metadata": {},
   "source": [
    "#### Doing it ourselves\n",
    "\n",
    "In this case of simulation, we will do the simulation ourselves, ensuring that we do not specify an illogical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010fea1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    yearJoined\n",
       " 0         2018\n",
       " 1         2018\n",
       " 2         2016\n",
       " 3         2018\n",
       " 4         2018\n",
       " ..         ...\n",
       " 995       2014\n",
       " 996       2018\n",
       " 997       2018\n",
       " 998       2018\n",
       " 999       2015\n",
       " \n",
       " [1000 rows x 1 columns],\n",
       "     userJoined\n",
       " 0       bronze\n",
       " 1     inactive\n",
       " 2     inactive\n",
       " 3       bronze\n",
       " 4         gold\n",
       " ..         ...\n",
       " 995     bronze\n",
       " 996   inactive\n",
       " 997   inactive\n",
       " 998     silver\n",
       " 999     silver\n",
       " \n",
       " [1000 rows x 1 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user status\n",
    "years      = ['2014', '2015', '2016', '2017', '2018']\n",
    "\n",
    "userStatus = ['bronze', 'silver', 'gold', 'inactive']\n",
    "\n",
    "userYears  = np.random.choice(years, 1000, \n",
    "                             p = [0.1, 0.1, 0.15, 0.30, 0.35])\n",
    "\n",
    "userStats  = np.random.choice(userStatus, 1000, \n",
    "                             p = [0.5, 0.3, 0.1, 0.1])\n",
    "\n",
    "yearJoined = pd.DataFrame({'yearJoined': userYears})\n",
    "\n",
    "userJoined = pd.DataFrame({'userJoined': userStats})\n",
    "\n",
    "yearJoined, userJoined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90340bf5",
   "metadata": {},
   "source": [
    "Note that there are already many rules/assumptions integrated into the simulation just in these lines of code. We stipulate probabilities specific to the years in which members joined. We also made the user's status completely independent of the year they joined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7ac92",
   "metadata": {},
   "source": [
    "#### Doing it ourselves\n",
    "In the next step, we will create a table indicating when members opened emails each week. Here, we will define our organization's behavior: sending three emails per week. We will also define distinct patterns of user behavior in relation to email:\n",
    "- never opens the email;\n",
    "- constant level of engagement/email opening rate;\n",
    "- increase or decrease in the level of engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff02c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EMAILS_SENT_WEEKLY = 3\n",
    "\n",
    "# defining multiple functions for different patterns\n",
    "def never_opens(period_rng):\n",
    "    return []\n",
    "\n",
    "def constant_open_rate(period_rng):\n",
    "    n, p = NUM_EMAILS_SENT_WEEKLY, np.random.uniform(0, 1)\n",
    "    num_opened = np.random.binomial(n, p, len(period_rng))\n",
    "    return num_opened\n",
    "\n",
    "def increasing_open_rate(period_rng):\n",
    "    return open_rate_with_factor_change(period_rng,\n",
    "                                        np.random.uniform(1.01, \n",
    "                                                          1.30))\n",
    "\n",
    "def decreasing_open_rate(period_rng):\n",
    "    return open_rate_with_factor_change(period_rng,\n",
    "                                       np.random.uniform(0.5,\n",
    "                                                         0.99))\n",
    "\n",
    "def open_rate_with_factor_change(period_rng, fac):\n",
    "    if len(period_rng) < 1:\n",
    "        return []\n",
    "    times = np.random.randit(0, len(period_rng),\n",
    "                             int(0.1 * len(period_rng)))\n",
    "    num_opened = np.zeros(len(period_rng))\n",
    "    for prd in range(0, len(period_rng), 2):\n",
    "        try:\n",
    "            n, p = NUM_EMAILS_SENT_WEEKLY, np.random.uniform(0, \n",
    "                                                             1)\n",
    "            num_opened[prd:(prd + 2)] = np.random.binomial(n, p,\n",
    "                                                           2)\n",
    "            p = max(min(1, p * fac), 0)\n",
    "        except:\n",
    "            num_opened[prd] = np.random.binomial(n, p, 1)\n",
    "    for t in range(len(times)):\n",
    "        num_opened[times[t]] = 0\n",
    "    return num_opened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d4efa",
   "metadata": {},
   "source": [
    "Definimos funções para simular quatro tipos distintos de comportamentos:\n",
    "\n",
    "*Usuários que nunca abrem os emails*\n",
    "- never_opens()\n",
    "\n",
    "*Usuários que abrem aproximadamente o mesmo número de emails todas as semanas*\n",
    "- constant_open_rate()\n",
    "\n",
    "*Usuários que abrem um número decrescente de emails a cada semana*\n",
    "- decreasing_open_rate()\n",
    "\n",
    "*Usuários que abrem um número crescente de emails a cada semana*\n",
    "- increasing_open_rate()\n",
    "\n",
    "\n",
    "We ensure that those with increasing interest or those who lose interest over time are simulated in the same way with the *open_rate_with_factor_change()* function via the *increasing_open_rate()* and *decreasing_open_rate()* functions\n",
    "\n",
    "It is also necessary to create a system to model donation behavior. We don't want to be too naive, or our siulation won't provide insight into what we should expect. In other words, we want to build our existing hypotheses about user behavior within the model, and then test whether simulations based on these hypotheses match what we see in real data. Next, we'll adopt an imprecise but non-deterministic donation behavior that relates to the number of emails a user has opened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c702d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "## donation behavior\n",
    "def produce_donations(period_rng, user_behavior, num_emails, \n",
    "                      user_id, user_join_year):\n",
    "    donation_amounts = np.array([0, 25, 50, 75, 100, 250, 500,\n",
    "                                  1000, 1500, 2000])\n",
    "    user_has = np.random.choice(donation_amounts)\n",
    "    email_fraction = num_emails / (NUM_EMAILS_SENT_WEEKLY * len(period_rng))\n",
    "    user_gives = user_has * email_fraction\n",
    "    user_gives_idx = max(min(user_gives_idx,\n",
    "                             len(donation_amounts) - 2),\n",
    "                        1)\n",
    "    num_times_gave = np.random.randint(0, len(period_rng), num_times_gave)\n",
    "    dons = pd.DataFrame({'user'      : [],\n",
    "                         'amount'    : [],\n",
    "                         'timestamp' : []})\n",
    "    for n in range(num_times_gave):\n",
    "        donation = donation_amounts[user_gives_idx + np.random.binomial(1, .3)]\n",
    "        ts       = str(period_rng[times[n]].start_time + random_weekly_time_delta())\n",
    "        dons     = dons.append(pd.DataFrame(\n",
    "                     {'user'      : [user_id],\n",
    "                      'amount'    : [donation],\n",
    "                      'timestamp' : [ts]}))\n",
    "        \n",
    "    if dons.shape[0] > 0:\n",
    "        dons = dons[dons.amount != 0]\n",
    "        ## We do not report the absence of a donation event,\n",
    "        ## as this would not be recorded in a database\n",
    "        \n",
    "    return dons\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8bdec5",
   "metadata": {},
   "source": [
    "We follow some steps so that the code generates realistic behavior:\n",
    "- the total number of donations depends on how long someone has been a user;\n",
    "- we generate an ownership status per user, based on the behavioral hypothesis that the amount donated will be related to a stable amount that a person would have reserved to make donations;\n",
    "\n",
    "Since user behaviors are tied to specific *timestamps*, we will need to choose the weeks each user donated and during which period of that week they donated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca170663",
   "metadata": {},
   "outputs": [],
   "source": [
    "## utility function to choose a random time during the week\n",
    "def random_weekly_time_delta():\n",
    "    days_of_week     = [d for d in range(7)]\n",
    "    hours_of_day     = [h for h in range(11, 23)]\n",
    "    minute_of_hour   = [m for m in range(60)]\n",
    "    second_of_minute = [s for s in range(60)]\n",
    "    \n",
    "    return pd.Timedelta(str(np.random.choice(days_of_week)) + \"days\") + pd.Timedelta(str(np.random.choice(hours_of_day)) + \"hours\") + pd.Timedelta(str(np.random.choice(minute_of_hour)) + \"minutes\") + pd.Timedelta(str(np.random.choice(second_of_minute)) + \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed03b73",
   "metadata": {},
   "source": [
    "Now, we will group the components developed to simulate a certain number of users and associated events in order to ensure that the events only occur after a user joins, and that a user's email events have some relationship with the donation events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c27ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors         = [never_opens,\n",
    "                     constant_open_rate,\n",
    "                     increasing_open_rate,\n",
    "                     decreasing_open_rate]\n",
    "user_behaviors    = np.random.choice(behaviors, 1000,\n",
    "                                    [0.2, 0.5, 0.1, 0.2])\n",
    "rng               = pd.period_range('2015-02-14', '2018-06-01', freq = 'W')\n",
    "emails            = pd.DataFrame({'user'       : [],\n",
    "                                  'amount'     : [],\n",
    "                                  'timestamp'  : []})\n",
    "donations         = pd.DataFrame({'user'       : [],\n",
    "                                  'amount'     : [],\n",
    "                                  'timestamp'  : []})\n",
    "\n",
    "for idx in range(yearJoined.shape[0]):\n",
    "    ## Randomly generates the date a user would have joined\n",
    "    join_date = pd.Timestamp(yearJoined.iloc[idx].yearJoined) + pd.Timedelta(str(np.random.randint(0, 365)) + 'days')\n",
    "    join_date = min(join_date, pd.Timestamp('2018-06-01'))\n",
    "    \n",
    "    ## User must not have current timestamps before joining\n",
    "    user_rng  = rng[rng > join_date]\n",
    "    \n",
    "    if len(user_rng) < 1:\n",
    "        continue\n",
    "    \n",
    "    info = user_behaviors[idx](user_rng)\n",
    "    if len(info) == len(user_rng):\n",
    "        emails = emails.append(pd.DataFrame({'user'        : [idx] * len(info),\n",
    "                                             'week'        : [str(r.start_time) for r in user_rng],\n",
    "                                             'emailsOpened': info}))\n",
    "        donations = donations.append(produce_donation(user_rng, user_behaviors[idx],\n",
    "                                                      sum(info), idx, join_date.year))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
