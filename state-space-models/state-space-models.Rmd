---
title: "state-space-models"
author: "Della"
date: "2024-11-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# State Space Models for Time Series

State space models (MMEs) are similar to previous statistical models, but with a more "real and practical" motivation. They address difficulties that arise in real engineering problems, 
such as how to factor measurement error when making estimates and how to introduce prior knowledge or opinions into them.

State space models assume a world in which the true state cannot be directly calculated, we only have an inference of what can be measured. State space models also rely on specifying 
the dynamics of a system, for example, how the true state of the world evolves over time due to internal dynamics and external forces applied to a system.

Even though you may have never seen state space models in a mathematical context before, you have probably used them in your everyday life. For example, imagine a driver weaving through 
traffic. You try to determine where the driver is going and how you can best defend yourself. If the driver is drunk, you can call the police, whereas if he is distracted for a reason that will never happen again, you probably won't get involved. In the next few seconds or minutes, you would update your own state space model of that driver, before deciding what to do.

A classic example of where you would use a state space model is in launching a rocket. We know Newton's Laws, so we can write down the rules for the dynamics of the system and what the 
movement should be like over time. We also know that our GPS, sensors, or other type of location tracking will have some measurement error, which we can quantify and try to factor into the uncertainty of our calculations. Finally, we know that we cannot measure the action of all the forces in the world on a given rocket, as the system presents many uncertainties. That is, we want it to be robust when it comes to unknown sources of noise, perhaps solar wind, terrestrial wind or both.

Two different historical trends have resulted in the development of state space models and have sparked interest in the types of problems they address. Rockets and spacecraft dominated 
the skies, as did navigation systems for submarines and all manner of other automated inventions that required estimation of a state of the system that could not be measured. As researchers thought about how to estimate the state of the system, they began to develop state-space methods, particularly to disambiguate measurement errors from other types of uncertainty in the system. This led to the first uses of state space methods.

Likewise, during this period, data recording technology and the computing associated with it also evolved. This has resulted in the creation of much larger data sets for **time series**, 
including measurements from large or more detailed **time series** data sets. As more **time series** data becomes available, more data-intensive methods for this same data are being developed along with new thinking about state space modeling. In this chapter, we will study the following commonly used state space methods:
- the Kalman filter applied to a Gaussian linear model;
- hidden Markov models;
- Bayesian structural **time series**;

In each of these cases, the use of such models is quite accessible and well implemented. For each model, we will seek some intuition for the mathematics and analyze what type of data is 
appropriate for the method. Lastly, we'll look at code examples for each method. In each of them, we will make a distinction between what we observe and the state that generated our observations. By estimating the underlying state based on observations, we can divide our work into different stages or categories:

*<u>Filtering</u>:*
- using the measurement at time *t* to update our estimate of the state at time *t*;

*<u>Forecast</u>:*
- using the measurement at time *t* - 1 in order to generate a prediction for the expected state at time *t* (enabling the expected measurement at time *t* as well);

*<u>Smoothing</u>:*
- using measurement over a time interval that includes *t*, both before and after, to estimate what the true state was at time *t*;

The mechanisms of these operations tend to be similar, although the differences are important. Filtering is a way of deciding how to compare the most recent information to previous 
information when updating our state estimate. Forecasting is the prediction of the future state, without any information about the future. Smoothing is the use of past and future information to make the best estimate of the state at a given time.


## State Space Models: Pros and Cons

Data space models can be used for deterministic and stochastic applications, such as continuous samples and discrete samples of data. This alone gives us an idea of its usefulness and 
remarkable flexibility. The flexibility of state space models maximizes the advantages and disadvantages of this class of models.

A state space model has many positive aspects. It makes it possible to model what is often most interesting in a **time series*: the dynamic process and processes that generate the noisy 
data being analyzed, rather than just the noisy data itself. To begin with, with a state space model, we introduce a *causality* model into the modeling process to explain what is driving a process. This is advantageous for cases where we have strong theories or reliable knowledge about how a system works and where we want our model to help us identify more details about the overall dynamics that we are already familiar with.

A state space model allows coefficients and parameters to change over time, meaning it allows behavior to change over time. It is not necessary to impose a stationarity condition on our 
data when using a state space model. This is something totally different from the models we looked at previously, in which a stable process is assumed and modeled with just one set of coefficients, rather than time-varying coefficients. However, a state space model also has disadvantages, and often the positive aspects of this model are also its weaknesses:

- because state space models are very flexible, there are many parameters to define and many forms that a state space model can take. This means that the properties of a specific state 
space model have often not been studied in depth. When creating a tailored state space model for your **time series** data, you will be unlikely to find statistics books or academic research articles where others have studied this same model as well. Thus, you are on less firm ground when it comes to understanding the model's performance or errors made;
- state space models can be quite heavy in terms of computational resources, as they have many parameters. Furthermore, the high number of parameters in some types of models means we 
run the risk of overfitting, especially if there is not a lot of data.

## The Kalman filter

The Kalman filter is an advanced and widely implemented method for incorporating new information from a **time series** and intelligently integrating it with previously known 
information to estimate an underlying state. The Kalman filter had one of its first uses on the Apollo 11 mission - it was chosen when NASA engineers realized that onboard computing resources made other, more memory-intensive position estimation techniques unfeasible. Kalman filter is easy to calculate and does not require the storage of previous data to make present estimates or future predictions.

### Overview

Kalman filter has a reasonable number of quantities to track, and is an iterative, somewhat circular process, with many related quantities. For this reason, we will not derive the 
Kalman filter equations, rather we will take a high-level overview of these equations to get a sense of how they work.

Starting with a linear Gaussian model, assuming that our state and observations have the following dynamics:

*x<sub>t</sub> = F × x<sub>t-1</sub> + B × μ<sub>t</sub> + w<sub>t</sub>*

*y<sub>t</sub> = A × x<sub>t</sub> + v<sub>t</sub>*

That is, the state at time *t* is a function of the state at the previous time interval (*F × x<sub>t-1</sub>*), and an external force term (*B × μ< sub>t</sub>*) and a stochastic term 
(*w<sub>t</sub>*). Likewise, the measurement at time *t* is a function of the state at time *t* and a stochastic error term, measurement error.

We see here a filtering step - that is, a decision about how to use the measurement at time *t* to update our state estimate at time *t*. Recall that we postulate a situation in which we 
can observe only *y<sub>t</sub>* and make inferences about the state, but we can never be sure of the exact state. We see above that the quantity *K<sub>t</sub>* establishes a balance in our estimate between the old information (*$\overset{\wedge}{x}$<sub>t-1</sub>* ) and the new ones (*y<sub>t</sub>*).

Now, to detail things even more, let's define some terms. We use *P*, to represent our estimate of the covariance of our state (it can be a scalar or a matrix, it will depend on whether 
the state is univariate or multivariate, the latter being more common). *P$-$<sub>t</sub>* is the estimate for *t* before our measurement at time *t* is taken into account.

We also use *R* to represent the variance of the measurement error, the variance of *v<sub>t</sub>*, which again can be a scalar or a covariance matrix depending on the dimensionality 
of the measurements. In general, *R* is used for a system as it represents the well-known physical properties of a given sensor or measuring device. The appropriate value for *w<sub>t</sub>*, *Q*, is less well defined and subject to adjustment during the modeling process.

Next, we will start with a process that we know or estimate values of *x* and *P* at time 0. Then, we move forward in times after time 0, we adopt an iterative process with a prediction 
and update phase, with the prediction coming first, followed by the update/filtering phase and so on:

*$\overset{\wedge}{x}$<sub>t</sub> = F × $\overset{\wedge}{x}$<sub>t-1</sub> + B × μ<sub>t</sub>*

*P$-$<sub>t</sub> = F × P$-$<sub>t-1</sub> × \( F^T \) + Q*

*<u>Filtragem</u>:*

- *$\overset{\wedge}{x}$<sub>t</sub> = $\overset{\wedge}{x}-$<sub>t</sub> + K<sub>t</sub> × (y<sub>t</sub> - A × $\overset{\wedge}{x}-$<sub>t</sub>)*

- *P<sub>t</sub> = (I - K<sub>t</sub> × A) × P$-$<sub>t</sub>*

where *K<sub>t</sub>*, the Kalman gain is:

- *K<sub>t</sub> = P$-$<sub>t</sub> × \( A^T \) × (A × P$-$<sub>t</sub> × \( A^T \) + R)\( ^-1 \)*

The easiest way to understand the process is to know that there are calculations performed to predict the values at time *t*, without a measurement for *y<sub>t</sub>* (the prediction), 
and then the steps performed at time *t*, after the known *y<sub>t</sub>* measurement (the filtering). To get started, the following values are required:

- estimates for *R* and *Q* - their covariance matrices for measurement error (easy to know) and state stochasticity (generally estimated), respectively;
- estimates or known values for your state at time 0, *$\overset{\wedge}{x}$<sub>0</sub>* (estimated based on *y<sub>0</sub>* );
- prior knowledge of which forces are planned to be applied at time *t* and how this impacts the states - that is, the matrix B and the value *μ<sub>t</sub>*;
- knowledge of the dynamics of the system that determines the state transition from one time interval to another, that is, F;
- knowledge of how the measurement depends on the state, i.e. A.

## Code for the Kalman Filter

Let's imagine a classic case: trying to track an object subject to Newton's laws with sensors prone to errors. We will generate a **time series** based on Newton's Laws, that is, the 
position of an object is a function of its speed and acceleration. We will struggle to perform discrete measurements even though the underlying movement is continuous. We will first determine a series of accelerations and then assume that position and velocity start at 0. Although this is not physically realistic, we will determine instantaneous acceleration changes at the beginning of each time interval and a constant acceleration value:

![*The position, speed and acceleration of the rocket*](https://github.com/DellaCortef/time-series-pocket-reference/blob/main/state-space-models/images/plotting-position-velocity-acceleration.R.png?raw=true)

We assumed that these variables would represent a complete description of the state, but the only data available to us is the position of the object and the fact that this data is only available from a noisy sensor. This sensor is × in the following code, and we will plot how the measured value relates to the actual position:

![*The true position (points) versus our noisy measurement (line). Note that the position x does not represent a perfect parabola due to the noise we inserted into the state transition equation*](https://github.com/DellaCortef/time-series-pocket-reference/blob/main/state-space-models/images/sensor-x.R.png?raw=true)

In the figure *plotting-position-velocity-acceleration*, we observe a constant acceleration (bottom plot) leading to a linearly increasing velocity (middle plot) to generate a shifting parabola shape (top position plot).

Now, we will apply the Kalman filter. First, we will write a general function to express our analysis and derivation.

We will apply this function so that only the position of the rocket is measurable (instead of acceleration or speed):

![*Kalman filtering - Position: True, Measured and Estimated: Muitas grandezas relacionadas: a posição (linha sólida); a posição real/verdadeira (linha tracejada); a estimativa de filtragem da posição (ou seja, a melhor estimativa para a posição no tempo t com medição no tempo t incorporada, representada pela linha pontilhada); e a previsão da posição (ou seja, a melhor estimativa para a posição no tempo t incorporada somente à dinâmica conhecida somada às medições no tempo t - 1, não incluindo o tempo t.*](https://github.com/DellaCortef/time-series-pocket-reference/blob/main/state-space-models/images/position-true-measured-estimated-kalman-filtering.R.png?raw=true)

The Kalman filter removes much of the noise from measurement error. The extent to which it does this will depend on our value for *R*, the measurement noise parameter, which depicts how much the filter should weight the most recent value relative to previous values. As we can see, the filter performs a satisfactory job of predicting the data. In particular, note that there is no lag between the predicted data and the actual data, suggesting that the method is only predicting the current value based on the last value. We just saw a simple example of the Kalman filter. The Kalman filter is widely studied, as it is very useful in a variety of applications, especially those in which the internal dynamics of the system are well understood. This makes it the ideal tool for the simple example of a rocket, in which we understand the dynamics that are guiding the system.

Note that, in this simple example, all the power and usefulness of the Kalman filter are not fully used. This helps a lot when, say, we have several types of measurements and calculate different magnitudes or measure the same thing simultaneously, with different devices. Furthermore, there are other applications for the Kalman filter that are worth studying if this is a promising area for your domain of interest.

One of the great benefits of the Kalman filter is its recursion. This means you don't need to look at every data point in every iteration of the process. On the contrary, in each time step, all the information from the previous time steps is already incorporated as best as possible into the few estimated parameters, i.e. the most recent state and the covariance estimate. The advantage of this method is that we can make updates intelligently just by using these "summary statistics" as measurements, and we already know how to weight them against the most recent data. This makes the Kalman filter quite an advantage in the real world, since time and computational resources are few and valuable. In many instances it is compatible with systems dynamics, where processes are relatively Markovian (no memory except the immediately preceding state), and we have a function of an underlying state that can only be computed with some error.

## Hidden Markov Models

Hidden Markov Models (HMMs) are quite useful and interesting to model a **time series**, as they are a rare instance of unsupervised learning in **time series** analysis. In other words, there is no correct and identified answer to consider training. An HMM is motivated by an intuition similar to the one we used when testing the Kalman filter earlier, that is, the idea that the variables we can observe may not be the most descriptive variables of the system. As with the Kalman filter applied to a linear Gaussian model, we assume the idea that the process has a state, and our observations provide information about this state. And once again an opinion is needed about how state variables influence what we can observe. In the case of HMM, we determined that the process is non-linear and characterized by jumps between discrete states.

### How the Model Works

An HMM postulates a system in which there are states that are not directly observable. The system is a Markov process, which means it is "memoryless" in the sense that the probabilities of future events can be fully calculated by considering only the current state of the system. In other words, knowing the current state of the system and its previous states is no more useful than knowing only its current state.

Markov processes are normally represented in matrices. For example, suppose we have a system oscillating between states A and B. But regardless of the state, the statistical probability of the system remaining in the same state was greater than the change to another state in any different time interval. A system of this type would be represented by the following matrix:

$$
\begin{array}{c c c}
   & A & B \\
A & 0.7 & 0.3 \\
B & 0.2 & 0.8 \\
\end{array}
$$

Suppose our system is in state A (1, 0). State B would be (0, 1). In this case, the probability of the system remaining in state A is 0.7, while the probability of the system reversing is 0.3. It is not necessary to know what states the system was in before its most recent time. A Markov process means just that.

A hidden Markov model represents the same type of system, except that we cannot directly influence the state of the system from our observations. Instead, our observations provide clues as to the state of the system.

Real use cases:

- identification of process changes in financial markets (https://perma.cc/JRT2-ZDVJ);
- classification, prediction and correction of DNA sequencing information (https://perma.cc/4V4A-53TZ);
- recognition of sleep stages as depicted in ECG data (https://perma.cc/G37Y-XBQH);

### How we fit the model

We are assuming that there is a state that we cannot directly measure, and there is no way to get a demonstrably correct answer in many of the data sets we could use this technique on. There is no magic formula for deriving the most likely sequence of hidden states to explain the observations, but it is possible to approach an estimate once we have fully specified the system. In an HMM, we postulate that the system is fully described with the following information:

- the *transition probability* of going *x(t)* to *x(t) + 1*. This is equivalent to specifying a matrix like the one just mentioned: the transition between states A and B. The size of the matrix would depend on the number of hypothetical states;
- the *emission probability* or the *observation probability y(t)* given *x(t)*;
- the initial state of the system;

In more concrete terms, see the list of variables necessary to characterize and adjust an HMM process:

- *Q = q<sub>1</sub>, q<sub>2</sub>, ..., q<sub>N</sub>*: the different states of the system;
- *A = a<sub>i,j</sub> = a<sub>1,1</sub>, a<sub>1,2</sub>, ..., a<sub>n, m</sub>*: transition probability matrix indicating the transition in any time interval given the change from state *i* to state *j*;
- *O = o<sub>1</sub>, o<sub>2</sub>, ..., o<sub>T</sub>*: a sequence of observations sampled from this process in order , which is a **time series** of observations;
- *b<sub>i(ot)</sub>* indicating the emission probabilities, that is, the probabilities of seeing a given observation value, *o<sub>t</sub>* if the state is *q <sub>i</sub>*;
- *p = p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>N*: the initial probability distributions, i.e. the probability that the system will start in the state *q<sub>1</sub>, q<sub>2</sub>, ..., q<sub>N</sub>*, respectively;

However, with real data, generally none of these variables are known. All that is known is the actual sequence of observables *y<sub>1</sub>, y<sub>2</sub>, ..., y<sub>T</sub>*.

#### Baum-Welch Algorithm

When estimating the parameters of a hidden Markov model, we use the *Baum-Welch algorithm*. It guides us in our complex task of estimating the values of all parameters.

In the case of two interrelated tasks, parameter estimation and probability maximization, we can use the *expectation-maximization* algorithm to iterate between two steps until an acceptable solution is found.

The first step in applying the Baum-Welch algorithm is to specify the likelihood function, which is the probability of observing a given sequence given the hypothesized parameters. In our case, the hypothetical parameters would be the mathematical parameters per postulated state.

For example, if we assume that states generate Gaussian outputs with means and standard deviations different from the observed values that depended on the state, and if we assume a two-state model, we can represent the model as *μ<sub>1</sub> , σ<sub>1</sub>*, *μ<sub>2</sub>* and *σ<sub>2</sub>* with *μ<sub>μ=i</sub>* indicating the average of *i-th* state and the *two-th* state indicating the standard deviation of the *i-th* state. This could describe the emission probabilities, and we represent them collectively as *θ*. We could also assume the sequence of states like *x<sub>1</sub>, x<sub>2</sub>, ..., x<sub>t</sub>* that we were not able to observe.

Then the likelihood function would describe the probability of observing the sequence we observed by considering the emission probability parameters (i.e. the probability of a given observation in a specific state) and the sequence of hidden states as an integral of all possible *Xsub>t</sub>* from *p(y<sub>1</sub>, y<sub>2</sub>, ..., y<sub>t</sub> | μ<sub >1</sub>, σ<sub>1</sub>, μ<sub>2</sub>, σ<sub>2</sub>, ..., μ<sub>N</sub>, σ<sub>Nt</sub>) = p(y<sub>1</sub>, y<sub>2</sub>, ..., y<sub>t</sub> | μ<sub>1</sub>, σ<sub>1</sub>, μ<sub>2</sub>, σ<sub>2</sub>, ..., μ<sub>N</sub>, σ<sub>N</sub>)*

#### Viterbi Algorithm

Once the parameters of an HMM process have been estimated, such as using the Baum-Welch algorithm, it is necessary to analyze the most likely series of underlying states considering the measured **time series** of observable values. Unlike the Baum-Welch algorithm, the Viterbi algorithm guarantees you the best solution to the questions asked. This is because it is a dynamic programming algorithm designed to fully and efficiently explore the range of possible adjustments so that, as the algorithm's path lengthens, there is no need to recalculate all possible paths for all durations. of the path.

##### - Example: Weather Prediction

Assume we have two hidden states (**Rainy** and **Sunny**) and three possible observations (**Walk**, **Shop**, and **Clean**) over three days.

##### 1. Define Model Parameters

- **States**:
  - Rainy
  - Sunny

- **Observations**:
  - Walk
  - Shop
  - Clean

- **Start Probabilities**:
  - Probability of the first day being Rainy or Sunny.

- **Transition Probabilities**:
  - Likelihood of changing states (e.g., Rainy → Sunny).

- **Emission Probabilities**:
  - Likelihood of observations given a state (e.g., Rainy → Walk).

##### - Overview of the Viterbi Algorithm

The Viterbi Algorithm is used to compute the most probable sequence of hidden states given the observ:

![Viterbi Algorithm: Possible Observations States](https://github.com/DellaCortef/time-series-pocket-reference/blob/main/state-space-models/images/viterbi-algorithm-possible-observations-states.R.png?raw=true)

![Viterbi Algorithm: Time Series: The Viterbi algorithm searches for all possible paths to explain a given observed time series, where a path indicates which state was occupied in each time interval](https://github.com/DellaCortef/time-series-pocket-reference/blob/main/state-space-models/images/viterbi-algorithm-time-series.R.png?raw=true)

### Tuning an HMM

We will use the **depmixS4** package. First, you need to define an appropriate **time series**:

We seek to use the stock market as an example through bull market (rising shares), bear market (falling shares), neutral market (stable shares), and panic market scenarios. A random number of days for a state to persist is selected, as are variables representing the emission probability distribution for each state (i.e., the variables *_mu* and *_sd*, indicating what type of values we expect to see measured in a given state).

We can get a sense of what our generated **time series** looks like and the frequency of each state by looking at how many days in the sample correspond to each *true.mean*, the variable we are using to track the state:

| true.mean | Frequency |
|-----------|-----------|
| 0.02      | 142       |
| 0.03      | 66        |
| 0.10      | 111       |